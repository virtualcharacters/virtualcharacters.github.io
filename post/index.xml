<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on VirtualCharacters</title>
    <link>https://example.com/post/</link>
    <description>Recent content in Posts on VirtualCharacters</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Sep 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ICAART2021</title>
      <link>https://example.com/p/icaart2021/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/icaart2021/</guid>
      <description>Data-driven agents for virtual character animation control offer great potential for both recreational and serious games and applications. For the characters to be most effective in these instances, the behaviour portrayed by output animation needs to be realistic, dynamic and responsive to live events and cues from the user. Current state-of-the-art work in the area has shown impressive results for using supervised learning to output select behaviours provided sufficient motion clips are available for training, but these methods only allow for limited dynamism.</description>
    </item>
    
  </channel>
</rss>
